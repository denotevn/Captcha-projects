{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08 15:09:05.959200: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-08 15:09:06.293937: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-08 15:09:06.293984: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-08 15:09:06.295553: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-08 15:09:06.448350: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-08 15:09:06.450322: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-08 15:09:08.811849: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from mltu.tensorflow.dataProvider import DataProvider\n",
    "from mltu.tensorflow.losses import CTCloss\n",
    "from mltu.tensorflow.callbacks import Model2onnx, TrainLogger\n",
    "from mltu.tensorflow.metrics import CWERMetric\n",
    "\n",
    "from mltu.preprocessors import ImageReader\n",
    "from mltu.transformers import ImageResizer, LabelIndexer, LabelPadding\n",
    "from mltu.augmentors import RandomBrightness, RandomRotate, RandomErodeDilate\n",
    "from mltu.annotations.images import CVImage\n",
    "\n",
    "from model import train_model\n",
    "from configs import ModelConfigs\n",
    "\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import stow\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import rarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all the images and labels in the dataset\n",
    "dataset_path = \"/home/tuandinh/Desktop/Captra_projects/Dataset\"\n",
    "dataset, vocab, max_len = [], set(), 0\n",
    "captcha_path = os.path.join(dataset_path, \"captcha_images_v2\")\n",
    "for file in os.listdir(captcha_path):\n",
    "    file_path = os.path.join(captcha_path, file)\n",
    "    # label = os.path.splitext(file)[0] # Get the file name without the extension\n",
    "    # dataset.append([file_path, label])\n",
    "    # vocab.update(list(label))\n",
    "    # max_len = max(max_len, len(label))\n",
    "\n",
    "configs = ModelConfigs()\n",
    "\n",
    "# Save vocab and maximum text length to configs\n",
    "configs.vocab = \"\".join(vocab)\n",
    "configs.max_text_length = max_len\n",
    "configs.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset, vocab, max_len = [], set(), 0\n",
    "captcha_path = os.path.join(dataset_path, \"Imgs Train and Test \")\n",
    "\n",
    "# Create a data provider for the dataset\n",
    "data_provider = DataProvider(\n",
    "    dataset=dataset,\n",
    "    skip_validation=True,\n",
    "    batch_size=configs.batch_size,\n",
    "    data_preprocessors=[ImageReader(CVImage)],\n",
    "    transformers=[\n",
    "        ImageResizer(configs.width, configs.height),\n",
    "        LabelIndexer(configs.vocab),\n",
    "        LabelPadding(max_word_length=configs.max_text_length, padding_value=len(configs.vocab))\n",
    "        ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
